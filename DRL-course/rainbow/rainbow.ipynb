{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation and notes on Noisy Dueling Double DQN with N-step PER.\n",
    "This will be some notes on how to build up the Rainbow DQN, but leaving out the categorization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from collections import namedtuple, deque\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualize and data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Game env\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "# Personal lib:\n",
    "import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. initialise game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# take test seed:\n",
    "use_test_seed = False\n",
    "test_seed = np.random.randint(low=1, high=1000)\n",
    "\n",
    "#Seed values from now on.\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Game values\n",
    "game = \"D:\\dev\\learning\\DRL-project\\DRL-course\\projects\\p1_navigation\\Banana.exe\"\n",
    "env = UnityEnvironment(file_name=game, seed=test_seed if use_test_seed else seed, no_graphics=False)\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# game info:\n",
    "action_size = brain.vector_action_space_size\n",
    "state = env_info.vector_observations[0]\n",
    "state_size = len(state)\n",
    "\n",
    "general_info = log.create_general_info(\"*general info:*\", game, seed, state_size, action_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters\n",
    "Here we go through all the hyperparameters\n",
    "### 2.1 model parameters\n",
    "Using a noisy DQN we need to have a initialised noise value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_init = 0.2                      # The amount of noise applied\n",
    "model_info = log.create_model_info(\"*model info:*\", std_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prioritised Experience Replay buffer parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = (2 ** 20)             # The space we use to store Experiences \n",
    "BATCH_SIZE = 512                    # Amount of replays we train on each update.\n",
    "RB_method = \"nstep_per\"             # Choice of replay buffer: nstep_per, (per, replay_buffer)=not_implemented\n",
    "PER_e = 0.01                        # Epsilon\n",
    "PER_a = 0.6                         # Alpha\n",
    "PER_b = 0.4                         # Beta init\n",
    "PER_bi = 0.00001                    # Beta increase is the increase in taking the most prioritiesed replays\n",
    "PER_aeu = 3                         # Absolute error upper is the max priority a replay can have\n",
    "PER_learn_start = 0                 # Used to populated the sumtree with replays\n",
    "n_step = 8                          # Used in the n-step implementation for choosing how many sequent replays we use.\n",
    "per_info = log.create_per_info(\"*per_info:*\", BUFFER_SIZE, BATCH_SIZE, \\\n",
    "                               RB_method, PER_e, PER_a, PER_b, PER_bi, PER_aeu, PER_learn_start, n_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Agent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99                       # Future discount value\n",
    "TAU = 1e-3                         # Amount we update the target model each update session (use_soft_update=True)\n",
    "LR = 0.00005                       # The learning rate of the model\n",
    "opt_eps = 1.5e-4                   # Adam epsilon (more info)\n",
    "UPDATE_MODEL_EVERY = 10            # The amount of steps between model updates \n",
    "UPDATE_TARGET_EVERY = 8000         # The amount of steps between target updates (use_soft_update=Flase)\n",
    "use_soft_update = True             # Wether we are updating the model using soft updates or copying model weights over.\n",
    "priority_method = \"reward\"         # Initialised priorities (reward, none=max_val, error=compute_error)\n",
    "\n",
    "agent_info = log.create_agent_info(\"*agent info:*\", GAMMA, TAU, LR, opt_eps,\n",
    "                               UPDATE_MODEL_EVERY, UPDATE_TARGET_EVERY, use_soft_update, priority_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 500                    # Number of training episodes\n",
    "evaluation_interval = 200         # Indicating how often we evaluate the current agent.\n",
    "max_t = 1000                      # The max number of steps before going into new episode (not used)\n",
    "train_info = log.create_train_info(\"*train_info:*\", episodes, evaluation_interval, max_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model and layers: Noisy Dueling DQN\n",
    "Noisy DQN is that we apply noise to the last layers to emulated exploration.\n",
    "Dueling DQN is that we split the last layer into two and compute an advangtage vector (How good are each action in this state) and a value (how good is the state). This helps us when training the network to have a... \n",
    "### 3.1 Noisy layer\n",
    "parameter explained:\n",
    "weight_mu:\n",
    "\n",
    "weight_sigma:\n",
    "\n",
    "register_buffer(\"weight_epsilon\"):\n",
    "\n",
    "bias_mu:\n",
    "\n",
    "bias_sigma:\n",
    "\n",
    "register_buffer(\"bias_epsilon\"):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedNoisyLinear(nn.Module):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_features,       # Number of input features\n",
    "                 out_features,      # Number of output features\n",
    "                 std_init,          # Amount of noise in layer\n",
    "                 seed=None,         # The env seed (if needed)     \n",
    "                 name=\"noisyLinear\" # Name for debugging\n",
    "                ):\n",
    "        super(FactorizedNoisyLinear, self).__init__()\n",
    "        if seed is not None:\n",
    "            self.seed = seed\n",
    "            torch.manual_seed(self.seed)\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.register_buffer(\"weight_epsilon\", torch.Tensor(out_features, in_features))\n",
    "        \n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.std_init = std_init\n",
    "        self.name = name\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Applying noise to the weights and bias to simulate exploring\n",
    "        :param x: The input state\n",
    "        :return: Linear translation with noisy weights and bias.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            weight = self.weight_mu + self.weight_sigma * self.weight_epsilon\n",
    "            bias = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias = self.bias_mu\n",
    "\n",
    "        y = F.linear(x, weight, bias)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-std, std)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
    "\n",
    "        self.bias_mu.data.uniform_(-std, std)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
    "\n",
    "    def reset_noise(self):\n",
    "        epsilon_in = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size)\n",
    "        return x.sign().mul_(x.abs().sqrt_())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Noisy Dueling DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyDDQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size, std_init, seed=None):\n",
    "        super(NoisyDDQN, self).__init__()\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "        self.action_size = action_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(self.state_size, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.value_stream = nn.Sequential(\n",
    "            FactorizedNoisyLinear(512, 512, std_init=std_init, seed=seed, name=\"value_stream1\"),\n",
    "            nn.ReLU(),\n",
    "            FactorizedNoisyLinear(512, 1, std_init=std_init, seed=seed, name=\"value_stream2\")\n",
    "        )\n",
    "\n",
    "        self.advantage_stream = nn.Sequential(\n",
    "            FactorizedNoisyLinear(512, 512, std_init=std_init, seed=seed, name=\"advantage_stream1\"),\n",
    "            nn.ReLU(),\n",
    "            FactorizedNoisyLinear(512, self.action_size, std_init=std_init, seed=seed, name=\"advantage_stream2\")\n",
    "        )\n",
    "\n",
    "        self.feature_layer.apply(self.init_weights)\n",
    "        self.value_stream.apply(self.init_weights)\n",
    "        self.advantage_stream.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.feature_layer(state)\n",
    "        value = self.value_stream(x)\n",
    "        advantage = self.advantage_stream(x)\n",
    "        q_values = value.expand_as(advantage) + (\n",
    "                advantage - advantage.mean(dim=state.dim() - 1, keepdim=True).expand_as(advantage))\n",
    "        return q_values\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, FactorizedNoisyLinear):\n",
    "                module.reset_noise()\n",
    "\n",
    "    def set_training(self, training):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, FactorizedNoisyLinear):\n",
    "                module.is_training = training\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 N-step Prioritiesed Experience Replay buffer\n",
    "In **the Prioritiesed Experience Replay** (PER) buffer, we do not chose the experience replays at random but weights the less seen or valueable experiences with a higher priority to better cover the information given from this experience.\n",
    "\n",
    "**The N-step** implementation aims to improve the temporal awareness of the agent, by combining the information of current state and action with the next N-steps into the future. This way we try to learn if a state is contributing to future rewards.\n",
    "\n",
    "We store the priorities of the experiences in a sumtree for faster search and updates.\n",
    "### 4.1 Sumtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree:\n",
    "    def __init__(self, capacity, seed=None):\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        self.capacity = int(capacity)\n",
    "        assert self.is_power_of_2(self.capacity), \"Capacity must be power of 2.\" + str(capacity)\n",
    "        # pointer to current index in data map.\n",
    "        self.data_pointer = 0\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.data_length = 0\n",
    "        # Priority tree.\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_length\n",
    "\n",
    "    def add(self, data, priority):\n",
    "        # Look at what index we want to put the experience\n",
    "        tree_index = self.data_pointer + self.capacity - 1\n",
    "        # Update data frame\n",
    "        self.data[self.data_pointer] = data\n",
    "        # Update the leaf\n",
    "        self.update(tree_index, priority)\n",
    "        # Add 1 to data_pointer\n",
    "        self.data_pointer = (self.data_pointer + 1) % self.capacity\n",
    "        if self.data_length < self.capacity:\n",
    "            self.data_length += 1\n",
    "\n",
    "    def update(self, tree_index, priority):\n",
    "        # change = new priority score - former priority score\n",
    "        change = priority - self.tree[tree_index]\n",
    "        self.tree[tree_index] = priority\n",
    "\n",
    "        # then propagate the change through tree\n",
    "        while tree_index != 0:\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "\n",
    "    def get_leaf(self, value):\n",
    "        parent_index = 0  # root\n",
    "        while True:\n",
    "            left_child_index = 2 * parent_index + 1\n",
    "            right_child_index = left_child_index + 1\n",
    "\n",
    "            # If we reach bottom, end the search\n",
    "            if left_child_index >= len(self.tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "            else:  # downward search, always search for a higher priority node\n",
    "                if value <= self.tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "                else:\n",
    "                    value -= self.tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "\n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "\n",
    "        return leaf_index, data_index, self.tree[leaf_index], self.data[data_index]\n",
    "\n",
    "    # Returns data given a data index\n",
    "    def get_data(self, data_index):\n",
    "        return self.data[data_index % self.capacity]\n",
    "\n",
    "    @staticmethod\n",
    "    def is_power_of_2(n):\n",
    "        return ((n & (n - 1)) == 0) and n != 0\n",
    "\n",
    "    @property\n",
    "    def total_priority(self):\n",
    "        return self.tree[0]  # the root\n",
    "\n",
    "    @property\n",
    "    def max_priority(self):\n",
    "        return np.max(self.tree[-self.data_length:])\n",
    "\n",
    "    @property\n",
    "    def min_priority(self):\n",
    "        return np.min(self.tree[-self.data_length:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 N-step PER buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerNStep:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __init__(self, capacity, batch_size, state_size, seed=None, epsilon=.001, alpha=.6, beta=.4, beta_increase=1e-3,\n",
    "                 absolute_error_upper=3, n_step=3, gamma=.99):\n",
    "        \"\"\"\n",
    "        :param capacity: Max amount of experience saved in the structure\n",
    "        :param epsilon: small value to insure all probabilities is not 0\n",
    "        :param alpha: introduces some randomness and to insure we don't train the same experience and overfit\n",
    "                      alpha=1 means greedy selecting the experience with highest priority\n",
    "                      alpha=0 means pure uniform randomness\n",
    "        :param beta: controls how much IS w affect learning\n",
    "                     beta>=0, starts close to 0 and get closer and closer to 1\n",
    "                     because these weights are more important in the end of learning when our q-values\n",
    "                     begins to convert\n",
    "        :param beta_increase: is the increase in beta for each sampling. 0.001 = 1e-3\n",
    "        :param absolute_error_upper: Setting a cap on how big an error (priority) can be.\n",
    "        :param n_step: store the most recent n-step transitions or experiences instead of the default 1.\n",
    "        :param gamma: This is the discount value\n",
    "        \"\"\"\n",
    "        ## Just like PER\n",
    "        # seeding\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "        # init\n",
    "        self.capacity = capacity\n",
    "        self.batch_size = batch_size\n",
    "        self.memory_tree = SumTree(self.capacity, seed)\n",
    "        self.experience = namedtuple(\"Experience\",\n",
    "                                     field_names=[\"timestep\", \"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.beta_increase = beta_increase\n",
    "        self.absolute_error_upper = absolute_error_upper\n",
    "        self.seed = seed\n",
    "\n",
    "        ## N-Step\n",
    "        self.t = 0  # Internal time step counter\n",
    "        self.n_step = n_step\n",
    "        self.n_step_buff = deque(maxlen=n_step)\n",
    "        self.gamma = gamma\n",
    "        self.blank_experience = self.experience(timestep=0,\n",
    "                                                state=torch.zeros(state_size, dtype=torch.float64),\n",
    "                                                action=None,\n",
    "                                                reward=0,\n",
    "                                                next_state=torch.zeros(state_size, dtype=torch.float64),\n",
    "                                                done=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory_tree)\n",
    "\n",
    "    def is_full(self):\n",
    "        return len(self.memory_tree) >= self.memory_tree.capacity\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "                - First, to sample a minibatch of size k the range [0, priority_total] is divided into k ranges.\n",
    "                - Then a value is uniformly sampled from each range.\n",
    "                - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
    "                - Then, we calculate IS weights for each minibatch element.\n",
    "\n",
    "                The difference here from the last structure is that we need to move to device\n",
    "                in the method calling this function.\n",
    "\n",
    "                so an example:\n",
    "                idxs, experiences, is_weights = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "                states = torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(device)\n",
    "                actions = torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).float().to(device)\n",
    "                rewards = torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(device)\n",
    "                next_states = torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(device)\n",
    "                dones = torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "                is_weights =  torch.from_numpy(is_weights).float().to(device)\n",
    "                \"\"\"\n",
    "\n",
    "        minibatch = []\n",
    "\n",
    "        idxs = np.empty((self.batch_size,), dtype=np.int32)\n",
    "        is_weights = np.empty((self.batch_size,), dtype=np.float32)\n",
    "\n",
    "        # Calculate the priority segment\n",
    "        # Divide the Range[0, ptotal] into n ranges\n",
    "        priority_segment = self.memory_tree.total_priority / self.batch_size  # priority segment\n",
    "\n",
    "        # Increase the beta each time we sample a new minibatch\n",
    "        self.beta = np.amin([1., self.beta + self.beta_increase])  # max = 1\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            \"\"\"\n",
    "            A value is uniformly sampled from each range\n",
    "            \"\"\"\n",
    "            a, b = priority_segment * i, priority_segment * (i + 1)\n",
    "\n",
    "            # This while is to counter that we find a leaf that is not populated yet.\n",
    "            # It happens when the buffer size is very large.\n",
    "            leaf_index, data_index, priority, data = 0, 0, 0, 0\n",
    "            while data == 0:\n",
    "                value = np.random.uniform(a, b)\n",
    "\n",
    "                \"\"\"\n",
    "                Experience that corresponds to each value is retrieved\n",
    "                \"\"\"\n",
    "                leaf_index, data_index, priority, data = self.memory_tree.get_leaf(value)\n",
    "\n",
    "            # P(i) = p_i**a / sum_k p_k**a\n",
    "            sampling_probabilities = priority / self.memory_tree.total_priority\n",
    "\n",
    "            # (1/N * 1/P(i))**b and to normalize it we divide with max_weight\n",
    "            # So is_weights[i] = (1/N * 1/P(i))**b\n",
    "            is_weights[i] = np.power(self.batch_size * sampling_probabilities, -self.beta)\n",
    "\n",
    "            idxs[i] = leaf_index\n",
    "            minibatch.append(data)\n",
    "        is_weights /= is_weights.max()\n",
    "        return idxs, minibatch, is_weights\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done, error=None):\n",
    "        exp = self.experience(self.t, torch.from_numpy(state), action, reward, torch.from_numpy(next_state), done)\n",
    "        self.n_step_buff.append(exp)\n",
    "        self.t = (0 if done else self.t + 1)\n",
    "        if len(self.n_step_buff) < self.n_step:\n",
    "            return None\n",
    "        exp, priority = self._get_n_step_info(self.n_step_buff, self.gamma)\n",
    "        priority = min((abs(priority) + self.epsilon) ** self.alpha, self.absolute_error_upper)\n",
    "        self.memory_tree.add(exp, priority)\n",
    "\n",
    "    def update_memory_tree(self, idxs, errors):\n",
    "        errors = errors + self.epsilon\n",
    "        clipped_errors = np.minimum(errors, self.absolute_error_upper)\n",
    "        ps = np.power(clipped_errors, self.alpha)\n",
    "\n",
    "        for idx, p in zip(idxs, ps):\n",
    "            self.memory_tree.update(idx, p)\n",
    "\n",
    "    def _get_n_step_info(self, n_step_buff, gamma):\n",
    "        timestep, org_state, org_action, _, _, _ = n_step_buff[0]\n",
    "        relevant_transitions = []\n",
    "        for transition in list(n_step_buff):\n",
    "            if timestep == transition.timestep:\n",
    "                relevant_transitions.append(transition)\n",
    "                timestep += 1\n",
    "            else:\n",
    "                break\n",
    "        # Take last element in deque and add the reward\n",
    "        rew, n_state, done = relevant_transitions[-1][-3:]\n",
    "        for transition in reversed(relevant_transitions[:-1]):\n",
    "            reward, n_s, d = transition.reward, transition.next_state, transition.done\n",
    "            rew = reward + gamma * rew * (1 - done)\n",
    "            n_state, done = (n_s, d) if d else (n_state, done)\n",
    "        return self.experience(timestep, org_state, org_action, rew, n_state, done), rew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Double DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleDQN:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __init__(self,\n",
    "                 state_size, action_size, models, replay_buffer, seed=None, BATCH_SIZE=64,\n",
    "                 GAMMA=0.99, TAU=1e-3, LR=5e-4, UPDATE_MODEL_EVERY=4, UPDATE_TARGET_EVERY=1000,\n",
    "                 use_soft_update=False, priority_method=\"reward\", PER_learn_start=0):\n",
    "        # seed for comparison\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            torch.manual_seed(self.seed)\n",
    "        # Hyper parameters:\n",
    "        self.state_size = state_size                       # Not used only for debugging\n",
    "        self.action_size = action_size                     # Not used only for debugging\n",
    "        self.batch_size = BATCH_SIZE                       \n",
    "        self.gamma = GAMMA\n",
    "        self.tau = TAU\n",
    "        self.lr = LR\n",
    "        self.UPDATE_MODEL_EVERY = UPDATE_MODEL_EVERY\n",
    "        self.UPDATE_TARGET_EVERY = UPDATE_TARGET_EVERY\n",
    "        self.use_soft_update = use_soft_update\n",
    "        self.priority_method = priority_method\n",
    "        self.t_step = 0\n",
    "        self.learn_start = PER_learn_start\n",
    "\n",
    "        # Double DQN or QN:\n",
    "        self.model = models[0].to(self.device)\n",
    "        self.model_target = models[1].to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, eps=1.5e-4)\n",
    "\n",
    "        # N-step:\n",
    "        self.n_step = n_step\n",
    "\n",
    "        # Priority Experience Replay:\n",
    "        self.memory = replay_buffer\n",
    "        \n",
    "        # plotting:\n",
    "        self.losses = []\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Saves learning experience in memory tree and decides if it is time to update models.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            state: The state we are moving from.\n",
    "            action: What action we took.\n",
    "            reward: The reward from going from state to the next state\n",
    "            next_state: The state we end up in.\n",
    "            done: If the game terminated after this step.\n",
    "        \"\"\"\n",
    "        # Save experience in replay memory\n",
    "        if self.priority_method == \"None\":\n",
    "            error = None\n",
    "        elif self.priority_method == \"error\":\n",
    "            error = self.compute_error(state, action, reward, next_state, done)\n",
    "        else:\n",
    "            error = reward\n",
    "        self.memory.add(state, action, reward, next_state, done, error)\n",
    "\n",
    "        # Filling memory\n",
    "        if self.learn_start != 0:\n",
    "            self.learn_start -= 1\n",
    "            if self.learn_start % 1000 == 0:\n",
    "                print(\"\\tFilling memory: \\t{0}\".format(self.learn_start, end=\"\\r\"))\n",
    "            return\n",
    "        # Update t_step:\n",
    "        self.t_step += 1\n",
    "        if self.t_step % self.UPDATE_MODEL_EVERY == 0 and self.t_step % self.UPDATE_TARGET_EVERY == 0:\n",
    "            self.t_step = 0\n",
    "\n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        if self.t_step % self.UPDATE_MODEL_EVERY == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                loss = self.learn()\n",
    "                self.losses.append(loss)\n",
    "                if self.use_soft_update:\n",
    "                    self.soft_update(self.model, self.model_target, self.tau)\n",
    "\n",
    "        if not self.use_soft_update and self.t_step % self.UPDATE_TARGET_EVERY == 0:\n",
    "            self.update_target_model()\n",
    "            print(\"\\tTarget model updated\")\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "        # TODO: Question for reviewers, should i disable noise here? hence put it on eval mode\n",
    "        #       I do see a faster growth in avg score in shorter training period,\n",
    "        #       but this might be from less exploring, hence might be bad in the longer run.\n",
    "        #       The noise is applied to the sampled memories under model update,\n",
    "        #       so this is why we might not need it here?\n",
    "        # self.model.eval() # disable noise\n",
    "        with torch.no_grad():\n",
    "            action_values = self.model.forward(state)\n",
    "        # self.model.train() # enable noise\n",
    "        return np.argmax(action_values.detach().cpu().numpy())\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "                Params\n",
    "                ======\n",
    "                    experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples\n",
    "                    gamma (float): discount factor\n",
    "                \"\"\"\n",
    "        # PER:\n",
    "        idxs, experiences, is_weights = self.memory.sample()\n",
    "        is_weights = torch.from_numpy(is_weights).float().to(self.device)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(\n",
    "            self.device)\n",
    "        dones = torch.from_numpy(\n",
    "            np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(\n",
    "            self.device)\n",
    "        \n",
    "        #todo:: Test if this is ok.\n",
    "        # with torch.no_grad():\n",
    "        \n",
    "        # Getting the max action of local network (using weights w)\n",
    "        max_actions = self.model.forward(next_states).detach().max(1)[1].unsqueeze(1)\n",
    "\n",
    "        # Getting the Q-value for these actions (using weight w^-)\n",
    "        Q_targets_next = self.model_target.forward(next_states).detach().gather(1, max_actions)\n",
    "\n",
    "        # Compute Q targets for current states (TD-target)\n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.model(states).gather(1, actions)\n",
    "\n",
    "        \n",
    "        # Compute loss - Per: weighted loss computed and the priorities are updated\n",
    "        errors = torch.abs(Q_expected - Q_targets).detach().cpu()\n",
    "        self.memory.update_memory_tree(idxs, errors)\n",
    "        loss = (is_weights * F.mse_loss(Q_expected, Q_targets)).mean()\n",
    "        \n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        # Resetting the noise of the model\n",
    "        self.model.reset_noise()\n",
    "        self.model_target.reset_noise()\n",
    "        return loss.item() # Return loss for logging\n",
    "\n",
    "    def compute_error(self, state, action, reward, next_state, done):\n",
    "        \"\"\" Compute the error between model and model_target given one experience\n",
    "        \"\"\"\n",
    "        # Set to eval to avoid backpropergation:\n",
    "        self.model.eval() \n",
    "        self.model_target.eval()\n",
    "        with torch.no_grad():\n",
    "            state = torch.from_numpy(state).to(self.device)\n",
    "            next_state = torch.from_numpy(next_state).to(self.device)\n",
    "            action = torch.as_tensor(action).to(self.device)\n",
    "            val, max_actions_Snext_local = self.model_target(next_state).detach().max(0)\n",
    "\n",
    "            # Getting the Q-value for these actions (using weight w^-)\n",
    "            Q_targets_next = self.model_target(next_state).detach()[max_actions_Snext_local]\n",
    "\n",
    "            # Compute Q targets for current states (TD-target)\n",
    "            Q_targets = reward + (self.gamma * Q_targets_next * (1 - done))\n",
    "\n",
    "            # Get expected Q values from local model\n",
    "            Q_expected = self.model(state)[action]\n",
    "\n",
    "            error = np.abs((Q_expected - Q_targets).detach().cpu().numpy())\n",
    "        self.model.train()\n",
    "        self.model_target.train()\n",
    "        return error\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\" Hard update model parameters.\n",
    "            Copying the current weights from DDQN to the target model.\n",
    "        \"\"\"\n",
    "        self.model_target.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_update(local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and evaluate agent:\n",
    "and helping functions\n",
    "### 6.1 Visualizing and helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage(values, window, mode='same'):\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    sma = np.convolve(values, weights, mode)\n",
    "    return sma.tolist()\n",
    "\n",
    "\n",
    "def plot_score(scores, Ln_blue, Ln_olive, fig):\n",
    "    # print(\"plot:\")\n",
    "    mean_scores = []\n",
    "    mean_scores.append(0)\n",
    "    for i in range(0, len(scores), 5):\n",
    "        l = []\n",
    "        for j in range(5):\n",
    "            l.append(scores[i + j])\n",
    "        mean_scores.append(np.mean(l))\n",
    "    # print(mean_scores)\n",
    "    Ln_blue.set_ydata(mean_scores)\n",
    "    Ln_blue.set_xdata(range(0, len(scores)+1, 5))\n",
    "    if len(scores) >= 30:\n",
    "        yMA = movingaverage(scores, 30)\n",
    "        Ln_olive.set_ydata(yMA)\n",
    "        Ln_olive.set_xdata(range(0, len(scores)))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)\n",
    "    \n",
    "    plt.pause(0.1)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def unpack_braininfo(brain_name, all_brain_info):\n",
    "    brain_info = all_brain_info[brain_name]\n",
    "    next_state = brain_info.vector_observations[0]\n",
    "    reward = brain_info.rewards[0]\n",
    "    done = brain_info.local_done[0]\n",
    "    max_reached = brain_info.max_reached[0]\n",
    "    return next_state, reward, done, max_reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(agent, brain_name, test_env, n_episodes, train_episode=\"Loaded model\", model_save_file=None,\n",
    "         current_best=10000, set_fast_mode=True):\n",
    "    scores = []  # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    time_window = deque(maxlen=10)  # last 10 iter\n",
    "    agent.model.eval()\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        state = test_env.reset(train_mode=set_fast_mode)[brain_name].vector_observations[0]\n",
    "        score = 0\n",
    "        start = time.time()\n",
    "        max_reached = False\n",
    "        while not max_reached:\n",
    "            action = int(agent.act(state))\n",
    "            next_state, reward, done, max_reached = unpack_braininfo(brain_name, test_env.step(action))\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "        time_window.append(time.time() - start)\n",
    "        scores_window.append(score)  # save most recent score\n",
    "        scores.append(score)  # save most recent score\n",
    "        print(\n",
    "            '\\rTest: Episode {}\\tAverage Score: {:.2f}\\tthis Score: {:.2f}\\tAverage Time pr episode {:.2f} seconds'.format(\n",
    "                i_episode,\n",
    "                np.mean(\n",
    "                    scores_window),\n",
    "                score,\n",
    "                np.mean(\n",
    "                    time_window)),\n",
    "            end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('Test: \\rEpisode {}\\tAverage Score: {:.2f}\\tTime left {:.2f} seconds'.format(i_episode,\n",
    "                                                                                               np.mean(scores_window),\n",
    "                                                                                               np.mean(time_window) * (\n",
    "                                                                                                       n_episodes - i_episode)))\n",
    "            if np.mean(scores_window) >= current_best:\n",
    "                if model_save_file != None:\n",
    "                    torch.save(agent.model.state_dict(), str(model_save_file))\n",
    "                    current_best = np.mean(scores_window)\n",
    "    agent.model.train()\n",
    "    return '\\n\\ttrain_episode: {}\\t Average Score over {} episodes: {}'.format(str(train_episode), str(n_episodes),\n",
    "                                                                               np.mean(scores)), current_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, brain_name, train_env, file, save_img=\"plot.png\", save_file='checkpoint.pth',\n",
    "          n_episodes=2000000, evaluation_interval=200, plot=False, plot_title=\"title\"):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    if plot:\n",
    "        buffer = 1\n",
    "        min_score = 0\n",
    "        max_score = min_score + buffer\n",
    "        fig = plt.figure()\n",
    "        # fig, axs = plt.subplots(2, 1)\n",
    "        # score_ax = axs[0]\n",
    "        score_ax = fig.add_subplot(111)\n",
    "        score_line_blue, = score_ax.plot([0, 0])\n",
    "        score_line_olive, = score_ax.plot([0, 0], color='olive')\n",
    "        score_ax.set_ylim([min_score, max_score])\n",
    "        score_ax.set_xlim([0, 1])\n",
    "\n",
    "        # loss_ax = axs[1]\n",
    "        # loss_line_blue, = loss_ax.plot([0, 0])\n",
    "        # loss_ax.set_ylim([0, 10])\n",
    "        # loss_ax.set_xlim([0, 1])\n",
    "\n",
    "        plt.title(plot_title)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('score mean over 5 epoch')\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "    scores = []  # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    time_window = deque(maxlen=10)  # last 10 iter\n",
    "    best_avg = 13.0\n",
    "    eval_result = \"\\n## test result: \\n\\n\"\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        state = train_env.reset(train_mode=True)[brain_name].vector_observations[0]\n",
    "        score = 0\n",
    "        start = time.time()\n",
    "        max_reached = False\n",
    "        while not max_reached:\n",
    "            action = int(agent.act(state))\n",
    "            next_state, reward, done, max_reached = unpack_braininfo(brain_name, train_env.step(action))\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "        time_window.append(time.time() - start)\n",
    "\n",
    "        scores_window.append(score)  # save most recent score\n",
    "        scores.append(score)  # save most recent score\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tthis Score: {:.2f}\\tAverage Time pr episode {:.2f} seconds'.format(\n",
    "            i_episode,\n",
    "            np.mean(\n",
    "                scores_window),\n",
    "            score,\n",
    "            np.mean(\n",
    "                time_window)),\n",
    "            end=\"\")\n",
    "        if plot and i_episode % 5 == 0:\n",
    "            # score\n",
    "            # Update axis:\n",
    "            window = scores[-5:]\n",
    "            mean = np.mean(window)\n",
    "            if mean > max_score - buffer:\n",
    "                max_score = mean + buffer\n",
    "                score_ax.set_ylim([min_score, max_score])\n",
    "            if mean < min_score + buffer:\n",
    "                min_score = mean - buffer\n",
    "                score_ax.set_ylim([min_score, max_score])\n",
    "            score_ax.set_xlim([0, len(scores)])\n",
    "            # PLOT\n",
    "            fig = plot_score(scores, score_line_blue, score_line_olive, fig)\n",
    "\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tTime left {:.2f} seconds'.format(i_episode,\n",
    "                                                                                         np.mean(scores_window),\n",
    "                                                                                         np.mean(time_window) * (\n",
    "                                                                                                 n_episodes - i_episode)))\n",
    "            with open(file, \"a+\") as f:\n",
    "                f.write('\\tEpisode {}\\tAverage Score: {:.2f}\\n'.format(i_episode, np.mean(scores_window)))\n",
    "            if plot:\n",
    "                plt.savefig(save_img)\n",
    "\n",
    "        if np.mean(scores_window) >= best_avg:\n",
    "#             print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}\\tTime left {:.2f} seconds'.format(\n",
    "#                 i_episode,\n",
    "#                 np.mean(scores_window), np.mean(time_window) * (n_episodes - i_episode)))\n",
    "            # log_result, current_best = eval(agent, brain_name, train_env, 100, i_episode, save_file, best_avg)\n",
    "            # eval_result += log_result\n",
    "            # best_avg = current_best\n",
    "            debug =0\n",
    "\n",
    "        if i_episode % evaluation_interval == 0:\n",
    "            # Time for evaluation\n",
    "            log_result, current_best = evaluate(agent, brain_name, train_env, 100, i_episode, save_file, best_avg)\n",
    "            eval_result += log_result\n",
    "            best_avg = current_best\n",
    "\n",
    "    with open(file, \"a+\") as f:\n",
    "        f.write(eval_result)\n",
    "        f.write(\"\\n\\nbest score: \" + str(max(scores)) + \" at eps: \" + str(scores.index(max(scores))))\n",
    "    return scores, best_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500\tAverage Score: 14.36\tTime left 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  5.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  9.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  6.0,\n",
       "  2.0,\n",
       "  8.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  12.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  8.0,\n",
       "  5.0,\n",
       "  14.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  7.0,\n",
       "  4.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  13.0,\n",
       "  15.0,\n",
       "  10.0,\n",
       "  7.0,\n",
       "  11.0,\n",
       "  8.0,\n",
       "  2.0,\n",
       "  11.0,\n",
       "  4.0,\n",
       "  15.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  17.0,\n",
       "  14.0,\n",
       "  0.0,\n",
       "  3.0,\n",
       "  20.0,\n",
       "  6.0,\n",
       "  3.0,\n",
       "  18.0,\n",
       "  5.0,\n",
       "  13.0,\n",
       "  18.0,\n",
       "  8.0,\n",
       "  17.0,\n",
       "  6.0,\n",
       "  13.0,\n",
       "  9.0,\n",
       "  4.0,\n",
       "  13.0,\n",
       "  8.0,\n",
       "  5.0,\n",
       "  3.0,\n",
       "  15.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  9.0,\n",
       "  20.0,\n",
       "  10.0,\n",
       "  12.0,\n",
       "  14.0,\n",
       "  10.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  14.0,\n",
       "  17.0,\n",
       "  18.0,\n",
       "  15.0,\n",
       "  22.0,\n",
       "  12.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  11.0,\n",
       "  15.0,\n",
       "  22.0,\n",
       "  7.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  26.0,\n",
       "  12.0,\n",
       "  18.0,\n",
       "  19.0,\n",
       "  5.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  20.0,\n",
       "  15.0,\n",
       "  5.0,\n",
       "  17.0,\n",
       "  14.0,\n",
       "  16.0,\n",
       "  14.0,\n",
       "  16.0,\n",
       "  12.0,\n",
       "  16.0,\n",
       "  20.0,\n",
       "  17.0,\n",
       "  5.0,\n",
       "  9.0,\n",
       "  8.0,\n",
       "  19.0,\n",
       "  11.0,\n",
       "  20.0,\n",
       "  11.0,\n",
       "  5.0,\n",
       "  19.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  15.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  11.0,\n",
       "  20.0,\n",
       "  13.0,\n",
       "  12.0,\n",
       "  21.0,\n",
       "  17.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  9.0,\n",
       "  16.0,\n",
       "  9.0,\n",
       "  22.0,\n",
       "  18.0,\n",
       "  14.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  22.0,\n",
       "  12.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  20.0,\n",
       "  15.0,\n",
       "  17.0,\n",
       "  14.0,\n",
       "  16.0,\n",
       "  14.0,\n",
       "  5.0,\n",
       "  11.0,\n",
       "  8.0,\n",
       "  14.0,\n",
       "  15.0,\n",
       "  20.0,\n",
       "  14.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  12.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  17.0,\n",
       "  12.0,\n",
       "  18.0,\n",
       "  17.0,\n",
       "  7.0,\n",
       "  16.0,\n",
       "  10.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  20.0,\n",
       "  10.0,\n",
       "  7.0,\n",
       "  14.0,\n",
       "  22.0,\n",
       "  10.0,\n",
       "  7.0,\n",
       "  11.0,\n",
       "  13.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  20.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  14.0,\n",
       "  10.0,\n",
       "  14.0,\n",
       "  18.0,\n",
       "  20.0,\n",
       "  12.0,\n",
       "  10.0,\n",
       "  15.0,\n",
       "  14.0,\n",
       "  15.0,\n",
       "  9.0,\n",
       "  0.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  24.0,\n",
       "  16.0,\n",
       "  10.0,\n",
       "  6.0,\n",
       "  14.0,\n",
       "  17.0,\n",
       "  6.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  10.0,\n",
       "  16.0,\n",
       "  18.0,\n",
       "  14.0,\n",
       "  9.0,\n",
       "  12.0,\n",
       "  7.0,\n",
       "  8.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  20.0,\n",
       "  7.0,\n",
       "  17.0,\n",
       "  23.0,\n",
       "  21.0,\n",
       "  21.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  18.0,\n",
       "  17.0,\n",
       "  16.0,\n",
       "  17.0,\n",
       "  18.0,\n",
       "  16.0,\n",
       "  22.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  18.0,\n",
       "  11.0,\n",
       "  12.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  21.0,\n",
       "  22.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  11.0,\n",
       "  17.0,\n",
       "  6.0,\n",
       "  19.0,\n",
       "  15.0,\n",
       "  8.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  9.0,\n",
       "  16.0,\n",
       "  15.0,\n",
       "  2.0,\n",
       "  13.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  12.0,\n",
       "  15.0,\n",
       "  13.0,\n",
       "  25.0,\n",
       "  11.0,\n",
       "  17.0,\n",
       "  10.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  23.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  10.0,\n",
       "  21.0,\n",
       "  20.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  8.0,\n",
       "  20.0,\n",
       "  16.0,\n",
       "  19.0,\n",
       "  13.0,\n",
       "  24.0,\n",
       "  17.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  10.0,\n",
       "  6.0,\n",
       "  8.0,\n",
       "  12.0,\n",
       "  18.0,\n",
       "  17.0,\n",
       "  19.0,\n",
       "  11.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  12.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  13.0,\n",
       "  20.0,\n",
       "  17.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  16.0,\n",
       "  15.0,\n",
       "  6.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  21.0,\n",
       "  10.0,\n",
       "  20.0,\n",
       "  20.0,\n",
       "  14.0,\n",
       "  11.0,\n",
       "  13.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  7.0,\n",
       "  13.0,\n",
       "  8.0,\n",
       "  15.0,\n",
       "  11.0,\n",
       "  17.0,\n",
       "  12.0,\n",
       "  21.0,\n",
       "  17.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  8.0,\n",
       "  17.0,\n",
       "  21.0,\n",
       "  18.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  18.0,\n",
       "  19.0,\n",
       "  10.0,\n",
       "  16.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  20.0,\n",
       "  9.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  11.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  15.0,\n",
       "  17.0,\n",
       "  11.0,\n",
       "  17.0,\n",
       "  9.0,\n",
       "  17.0,\n",
       "  10.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  11.0,\n",
       "  8.0,\n",
       "  23.0,\n",
       "  9.0,\n",
       "  6.0,\n",
       "  10.0,\n",
       "  14.0,\n",
       "  21.0,\n",
       "  15.0,\n",
       "  20.0,\n",
       "  7.0,\n",
       "  22.0,\n",
       "  17.0,\n",
       "  20.0,\n",
       "  19.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  14.0,\n",
       "  18.0,\n",
       "  24.0,\n",
       "  13.0,\n",
       "  10.0,\n",
       "  19.0,\n",
       "  13.0,\n",
       "  15.0,\n",
       "  4.0,\n",
       "  16.0,\n",
       "  15.0,\n",
       "  20.0,\n",
       "  16.0,\n",
       "  26.0,\n",
       "  14.0,\n",
       "  20.0,\n",
       "  8.0,\n",
       "  6.0,\n",
       "  13.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  11.0,\n",
       "  20.0,\n",
       "  15.0,\n",
       "  23.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  17.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  11.0,\n",
       "  10.0,\n",
       "  12.0,\n",
       "  10.0,\n",
       "  18.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  5.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  15.0,\n",
       "  13.0,\n",
       "  15.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  14.0,\n",
       "  25.0,\n",
       "  18.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  16.0,\n",
       "  10.0,\n",
       "  18.0,\n",
       "  6.0,\n",
       "  13.0,\n",
       "  16.0,\n",
       "  13.0,\n",
       "  15.0],\n",
       " 15.1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create plot\n",
    "plot = True\n",
    "\n",
    "# Title of plot:\n",
    "title = \"model: NoisyDueling, agent: DoubleDQN, NSTEP_PER-\" + priority_method + \"Update: \"\n",
    "if use_soft_update:\n",
    "    title += \"soft\"\n",
    "else:\n",
    "    title += \"hard\"\n",
    "\n",
    "# Create data folder:\n",
    "base_dir = Path(\"saved\", \"test0\")\n",
    "counter = 0\n",
    "while base_dir.exists():\n",
    "    counter += 1\n",
    "    base_dir = Path(\"saved\", \"test\" + str(counter))\n",
    "base_dir.mkdir(parents=True)\n",
    "file = str(Path(base_dir, \"model_test.md\"))\n",
    "print(file)\n",
    "save_file = str(Path(base_dir, \"NoisyDuelingDoubleDQN_checkpoint.pth\"))\n",
    "save_image = str(Path(base_dir, \"plot.png\"))\n",
    "\n",
    "# Write hyperparameters to file\n",
    "with open(file, \"a+\") as f:\n",
    "    f.write(\"\\n# \" + str(title) + \"\\n\\n\")\n",
    "    f.write(general_info + \"\\n\")\n",
    "    f.write(model_info + \"\\n\")\n",
    "    f.write(agent_info + \"\\n\")\n",
    "    f.write(per_info + \"\\n\")\n",
    "    f.write(train_info + \"\\n\\n\")\n",
    "    f.write(\"\\n## train data: \\n\\n\")\n",
    "    \n",
    "# Create models\n",
    "models = (NoisyDDQN(state_size, action_size, std_init=std_init, seed=seed),\n",
    "          NoisyDDQN(state_size, action_size, std_init=std_init, seed=seed))\n",
    "# Create N-step PER buffer\n",
    "replay_buffer = PerNStep(BUFFER_SIZE, \n",
    "                         BATCH_SIZE,\n",
    "                         state_size=state_size,\n",
    "                         seed=seed,\n",
    "                         epsilon=PER_e,\n",
    "                         alpha=PER_a,\n",
    "                         beta=PER_b,\n",
    "                         beta_increase=PER_bi,\n",
    "                         absolute_error_upper=PER_aeu,\n",
    "                         n_step=n_step,\n",
    "                         gamma=GAMMA)\n",
    "\n",
    "agent = DoubleDQN(state_size,\n",
    "                     action_size,\n",
    "                     models,\n",
    "                     replay_buffer,\n",
    "                     seed=seed,\n",
    "                     BATCH_SIZE=BATCH_SIZE,\n",
    "                     GAMMA=GAMMA,\n",
    "                     TAU=TAU,\n",
    "                     LR=LR, \n",
    "                     UPDATE_MODEL_EVERY=UPDATE_MODEL_EVERY, \n",
    "                     UPDATE_TARGET_EVERY=UPDATE_TARGET_EVERY,\n",
    "                     use_soft_update=use_soft_update,\n",
    "                     priority_method=priority_method,\n",
    "                     PER_learn_start=PER_learn_start)\n",
    "\n",
    "train(agent, brain_name, env, file=file, save_img=save_image, save_file=save_file, n_episodes=episodes,\n",
    "      evaluation_interval=evaluation_interval, plot=plot, plot_title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unity",
   "language": "python",
   "name": "unity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
